{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING USING SCI-KIT LEARN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Sci-kit learn in short form sklearn\n",
    "2. Another python package / library for many operations.\n",
    "    -data preprocessing\n",
    "    -ML\n",
    "    -NN\n",
    "    -NLP\n",
    "    -Stats\n",
    "    .......\n",
    "3. SKlearn expects your data to be in the form of NUmpy array"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create A Model That can predict whether the customer will purchase the product from my shop based on \n",
    "customer's Location, Age and Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = pd.read_csv('pre-process_datasample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Country    9 non-null      object \n",
      " 1   Age        9 non-null      float64\n",
      " 2   Salary     9 non-null      float64\n",
      " 3   Purchased  10 non-null     object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "dataDF.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--SKlearn currently doesnt support Handling Missing Values in String Columns \n",
    "--You will need to use Pandas if You want to perform Imputation\n",
    "--Official name of filling the missing value is called Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF.Country.fillna(dataDF.Country.mode()[0] , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>France</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8   France  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rules for using SKLEARN\n",
    "--------------------------------\n",
    "1. Your data must be strictly a Numpy Array\n",
    "2. Sklearn Doesnt Support Handling Missing Values in Non-numeric Columns unfortunately\n",
    "3. Ensure your feature set is completely NUMERIC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Try to understand what is Feature and Label..\n",
    "-------------------------------------------------------\n",
    "Predictive Analytics, we find two types of variables\n",
    "1. Independent Variables (Features) input variables -- Location, Age, Salary\n",
    "--Whatever information you have is independant variable\n",
    "2. Dependent Variables (Label) output variables ------- Purchased\n",
    "--whatever you are predicting based on the information you have is dependant variable\n",
    "3. From above rules , feature should be completely numerical, but label having non-numeric also manageable.\n",
    "    and its fine for scikit learn.But not for other programming languages like R..\n",
    "    for Scikit learn alone its feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Country    10 non-null     object \n",
      " 1   Age        9 non-null      float64\n",
      " 2   Salary     9 non-null      float64\n",
      " 3   Purchased  10 non-null     object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "dataDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate Features and Label\n",
    "featuresDF = dataDF.iloc[:,:-1].values # -1 INDICATES..UPPER BOUND VALUE..end value +1\n",
    "labelDF = dataDF.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['France', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>France</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8   France  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['France', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Deal with Missing Values\n",
    "---------------------------------\n",
    "Step1: Import relevant package and class\n",
    "Step2: Create Object and Instantiate the Object\n",
    "Step3: Fit the Object With the Data (Performing Calc ....)\n",
    "Step4: Transform Your DataSet with Fitted Values (Applying VAlues in respective col data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Deal with Missing Values\n",
    "\n",
    "Step1: Import relevant package and class\n",
    ".impute is a package from sklearn and SimpleImputer is the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If you are not sure about SimpleImputer, where do you get help to understand about it?\n",
    "How do know about SimpleImputer, what it will do, from where we should get about this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmissing_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0madd_indicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Imputation transformer for completing missing values.\n",
       "\n",
       "Read more in the :ref:`User Guide <impute>`.\n",
       "\n",
       ".. versionadded:: 0.20\n",
       "   `SimpleImputer` replaces the previous `sklearn.preprocessing.Imputer`\n",
       "   estimator which is now removed.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "missing_values : int, float, str, np.nan or None, default=np.nan\n",
       "    The placeholder for the missing values. All occurrences of\n",
       "    `missing_values` will be imputed. For pandas' dataframes with\n",
       "    nullable integer dtypes with missing values, `missing_values`\n",
       "    should be set to `np.nan`, since `pd.NA` will be converted to `np.nan`.\n",
       "\n",
       "strategy : string, default='mean'\n",
       "    The imputation strategy.\n",
       "\n",
       "    - If \"mean\", then replace missing values using the mean along\n",
       "      each column. Can only be used with numeric data.\n",
       "    - If \"median\", then replace missing values using the median along\n",
       "      each column. Can only be used with numeric data.\n",
       "    - If \"most_frequent\", then replace missing using the most frequent\n",
       "      value along each column. Can be used with strings or numeric data.\n",
       "      If there is more than one such value, only the smallest is returned.\n",
       "    - If \"constant\", then replace missing values with fill_value. Can be\n",
       "      used with strings or numeric data.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "       strategy=\"constant\" for fixed value imputation.\n",
       "\n",
       "fill_value : string or numerical value, default=None\n",
       "    When strategy == \"constant\", fill_value is used to replace all\n",
       "    occurrences of missing_values.\n",
       "    If left to the default, fill_value will be 0 when imputing numerical\n",
       "    data and \"missing_value\" for strings or object data types.\n",
       "\n",
       "verbose : integer, default=0\n",
       "    Controls the verbosity of the imputer.\n",
       "\n",
       "copy : boolean, default=True\n",
       "    If True, a copy of X will be created. If False, imputation will\n",
       "    be done in-place whenever possible. Note that, in the following cases,\n",
       "    a new copy will always be made, even if `copy=False`:\n",
       "\n",
       "    - If X is not an array of floating values;\n",
       "    - If X is encoded as a CSR matrix;\n",
       "    - If add_indicator=True.\n",
       "\n",
       "add_indicator : boolean, default=False\n",
       "    If True, a :class:`MissingIndicator` transform will stack onto output\n",
       "    of the imputer's transform. This allows a predictive estimator\n",
       "    to account for missingness despite imputation. If a feature has no\n",
       "    missing values at fit/train time, the feature won't appear on\n",
       "    the missing indicator even if there are missing values at\n",
       "    transform/test time.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "statistics_ : array of shape (n_features,)\n",
       "    The imputation fill value for each feature.\n",
       "    Computing statistics can result in `np.nan` values.\n",
       "    During :meth:`transform`, features corresponding to `np.nan`\n",
       "    statistics will be discarded.\n",
       "\n",
       "indicator_ : :class:`~sklearn.impute.MissingIndicator`\n",
       "    Indicator used to add binary indicators for missing values.\n",
       "    ``None`` if add_indicator is False.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "IterativeImputer : Multivariate imputation of missing values.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.impute import SimpleImputer\n",
       ">>> imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
       ">>> imp_mean.fit([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])\n",
       "SimpleImputer()\n",
       ">>> X = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
       ">>> print(imp_mean.transform(X))\n",
       "[[ 7.   2.   3. ]\n",
       " [ 4.   3.5  6. ]\n",
       " [10.   3.5  9. ]]\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Columns which only contained missing values at :meth:`fit` are discarded\n",
       "upon :meth:`transform` if strategy is not \"constant\".\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\davea\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?SimpleImputer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step2: Create Object and Instantiate the Object\n",
    " --SimpleImputer works as calculation of mean and fill for missing values which are available in the data is represented as np.nan and \n",
    "--these should be filled with mean by imputation method    \n",
    " Plan of Action  --- Age --> Mean # Assumption only to explore :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "siAge = SimpleImputer(strategy='mean' , \n",
    "                   missing_values=np.nan)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--Plan of Action-----------Salary --> Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "siSalary = SimpleImputer(strategy='median',\n",
    "                        missing_values=np.nan)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "here \"si\" is called object...and strategy here is mean.....so object is called mean imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan == np.nan # always false"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step3: Fit the Object With the Data (Performing Calc ....)\n",
    ".fit() is a function in sklearn which will perform the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.0, 27.0, 30.0, 38.0, 40.0, 35.0, nan, 48.0, 50.0, 37.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF[:,1].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above data is in 1-D, but sklearn expects 2-d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.0],\n",
       "       [27.0],\n",
       "       [30.0],\n",
       "       [38.0],\n",
       "       [40.0],\n",
       "       [35.0],\n",
       "       [nan],\n",
       "       [48.0],\n",
       "       [50.0],\n",
       "       [37.0]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF[:,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF[:,[1]].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now it has become 2d DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[44. 27. 30. 38. 40. 35. nan 48. 50. 37.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d056080982aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msiAge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturesDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# calculates the mean of the column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;31m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             X = self._validate_data(X, reset=in_fit,\n\u001b[0m\u001b[0;32m    253\u001b[0m                                     \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                                     \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    638\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[44. 27. 30. 38. 40. 35. nan 48. 50. 37.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "siAge.fit(featuresDF[:,1]) # calculates the mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siAge.fit(featuresDF[:,[1]]) # calculates the mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siAge.fit(featuresDF[:,1].reshape(-1,1)) # same as above # SimpleImputer() is the default of strategy=\"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(strategy='median')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siSalary.fit(featuresDF[:,2].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step4: Transform Your DataSet with Fitted Values (Applying VAlues in respective col data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDF[:,[1]] = siAge.transform(featuresDF[:,[1]])\n",
    "featuresDF[:,[2]] = siSalary.transform(featuresDF[:,[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>France</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8   France  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 61000.0],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['France', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The above functions ( .fit() & .Transform() )  will be done with single function called .fit_transform()\n",
    "and syntax is : features[:,1] = siAge.fit_transform(features[:,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data processing can be done with two ways \n",
    "Using pandas , to fill the missing values .fillna will be used\n",
    "Using sklearn , .fit_transform will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One Hot Encoding for categorical variables\n",
    "# reshape is required because sklearn asks for 2d data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "fCountry = ohe.fit_transform(featuresDF[:,0].reshape(-1,1)) # .reshape(row , columns)\n",
    "fCountry                                      # row=-1 means till last rows, 1 means 1st column, i.e, contry"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[1., 0., 0.],-------France\n",
    "       [0., 0., 1.],-------Spain\n",
    "       [0., 1., 0.],-------Germany\n",
    "       [0., 0., 1.],-------Spain\n",
    "       [0., 1., 0.],-------Germany\n",
    "       [1., 0., 0.],-------France\n",
    "       [0., 0., 1.],-------Spain\n",
    "       [1., 0., 0.],-------France\n",
    "       [1., 0., 0.],-------France\n",
    "       [1., 0., 0.]])------France"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Sparse Matrix : If matrix i having lots of lots zeros,then sprase martrix will compresses matrixs having the zeros to reduc the memory size.\n",
    "--this sparse matrix is available in scipy library.\n",
    "--in general Scipy is used for stats.\n",
    "--see the example below"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ohe = OneHotEncoder()\n",
    "fCountry = ohe.fit_transform(featuresDF[:,0].reshape(-1,1))\n",
    "fCountry"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " The above code is with sparse matrix, so the result is 10*3 sparse matrix type with 10 atored elements in compressed sparse  row format..to save the memory allocation\n",
    " # the above data can not give for further preocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalFeatures = np.concatenate((fCountry, featuresDF[:,[1,2]]) , axis = 1) # to bring all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting=\"same_kind\")\n",
       "\n",
       "Join a sequence of arrays along an existing axis.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a1, a2, ... : sequence of array_like\n",
       "    The arrays must have the same shape, except in the dimension\n",
       "    corresponding to `axis` (the first, by default).\n",
       "axis : int, optional\n",
       "    The axis along which the arrays will be joined.  If axis is None,\n",
       "    arrays are flattened before use.  Default is 0.\n",
       "out : ndarray, optional\n",
       "    If provided, the destination to place the result. The shape must be\n",
       "    correct, matching that of what concatenate would have returned if no\n",
       "    out argument were specified.\n",
       "dtype : str or dtype\n",
       "    If provided, the destination array will have this dtype. Cannot be\n",
       "    provided together with `out`.\n",
       "\n",
       "    .. versionadded:: 1.20.0\n",
       "\n",
       "casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
       "    Controls what kind of data casting may occur. Defaults to 'same_kind'.\n",
       "\n",
       "    .. versionadded:: 1.20.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "res : ndarray\n",
       "    The concatenated array.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ma.concatenate : Concatenate function that preserves input masks.\n",
       "array_split : Split an array into multiple sub-arrays of equal or\n",
       "              near-equal size.\n",
       "split : Split array into a list of multiple sub-arrays of equal size.\n",
       "hsplit : Split array into multiple sub-arrays horizontally (column wise).\n",
       "vsplit : Split array into multiple sub-arrays vertically (row wise).\n",
       "dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
       "stack : Stack a sequence of arrays along a new axis.\n",
       "block : Assemble arrays from blocks.\n",
       "hstack : Stack arrays in sequence horizontally (column wise).\n",
       "vstack : Stack arrays in sequence vertically (row wise).\n",
       "dstack : Stack arrays in sequence depth wise (along third dimension).\n",
       "column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "When one or more of the arrays to be concatenated is a MaskedArray,\n",
       "this function will return a MaskedArray object instead of an ndarray,\n",
       "but the input masks are *not* preserved. In cases where a MaskedArray\n",
       "is expected as input, use the ma.concatenate function from the masked\n",
       "array module instead.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = np.array([[1, 2], [3, 4]])\n",
       ">>> b = np.array([[5, 6]])\n",
       ">>> np.concatenate((a, b), axis=0)\n",
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])\n",
       ">>> np.concatenate((a, b.T), axis=1)\n",
       "array([[1, 2, 5],\n",
       "       [3, 4, 6]])\n",
       ">>> np.concatenate((a, b), axis=None)\n",
       "array([1, 2, 3, 4, 5, 6])\n",
       "\n",
       "This function will not preserve masking of MaskedArray inputs.\n",
       "\n",
       ">>> a = np.ma.arange(3)\n",
       ">>> a[1] = np.ma.masked\n",
       ">>> b = np.arange(2, 5)\n",
       ">>> a\n",
       "masked_array(data=[0, --, 2],\n",
       "             mask=[False,  True, False],\n",
       "       fill_value=999999)\n",
       ">>> b\n",
       "array([2, 3, 4])\n",
       ">>> np.concatenate([a, b])\n",
       "masked_array(data=[0, 1, 2, 2, 3, 4],\n",
       "             mask=False,\n",
       "       fill_value=999999)\n",
       ">>> np.ma.concatenate([a, b])\n",
       "masked_array(data=[0, --, 2, 2, 3, 4],\n",
       "             mask=[False,  True, False, False, False, False],\n",
       "       fill_value=999999)\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if any doubt on axis=1, then check for \n",
    "?np.concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 61000.0],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
       "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [1.0, 0.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusions on processing of data\n",
    "# 1. performance wise both ways i.e,Pandas and sklearn both are same\n",
    "# 2. mermory for calculation also same because pandas also use numpy only\n",
    "# 3. only to aware both the procedures ..we have gone thru\n",
    "# 4. if organisation ahving not of pandas becuase of security standards or others\n",
    "#    then sklearn way is helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sparse Matrix EXample\n",
    "import numpy as np\n",
    "matrix1 = np.matrix([[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,1,2]])\n",
    "matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bytes\n",
    "import sys\n",
    "sys.getsizeof(matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compress the matrix with a goal to save memory space\n",
    "from scipy.sparse import csr_matrix\n",
    "compressedMatrix = csr_matrix(matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(compressedMatrix)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "this is the concept where this is used in winzip file compression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sparse matrix uses: \n",
    "-------------------\n",
    "---1.this is memory saving technic used for neural network, incase where images, videos and audio will take more in size, and that too NN works on top of RAM ..\n",
    "---2. effective utilization of program, if your are good programmer, you will maintain a matrix always in sparse matrix.\n",
    "---3. Example is Graphics rendering, Video rendering..takes lot of time..so to reduce time in rendering, then need to use sparse matrix.\n",
    "Explanation : when we say image, then it is inthe form of RGB, Image is nothing but matrix of 3 intensities.\n",
    "                red, green,blue.\n",
    " when we work on 1080p--Pixel..\n",
    " what is the normal HD video quality? it is 720.\n",
    " So size of the matrix is 720*1080..\n",
    " Is it not good idea to reduce the size of the image and video, especially screen of the video.\n",
    " \n",
    " 4. Real time face / road detection also takes lot of memory becuase of huge amount of matrices carries...so, this kind of applications are worked in mathematics with fundamental tecniques to reduce the size of the memory..\n",
    " this basic concept is called Sparse matrix.\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# When we use oneHotEncoder, the output will give with sparsing matrix, that is not enough to use for further programming,  instead we need proper dummy variable to give input to the ML.\n",
    "# to do prpoer dummy variable, we are doing disabling sparsity on the codong as (...., sparse=False)\n",
    "#One Hot Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
